import torch
import torch.nn as nn
import torch.nn.functional as F
from Backbone import resnet101
from FPN import FeaturePyramid


class RegressionModel(nn.Module):
    def __init__(self, num_features_in=256, num_anchors=3, feature_size=256):
        super(RegressionModel, self).__init__()

        self.conv1 = nn.Conv3d(num_features_in, feature_size, kernel_size=3, padding=1)
        self.act1 = nn.ReLU()

        self.conv2 = nn.Conv3d(feature_size, feature_size, kernel_size=3, padding=1)
        self.act2 = nn.ReLU()

        self.conv3 = nn.Conv3d(feature_size, feature_size, kernel_size=3, padding=1)
        self.act3 = nn.ReLU()

        self.conv4 = nn.Conv3d(feature_size, feature_size, kernel_size=3, padding=1)
        self.act4 = nn.ReLU()

        self.output = nn.Conv3d(feature_size, num_anchors * (1+4+1), kernel_size=3, padding=1)

    def forward(self, x):
        out = self.conv1(x)
        out = self.act1(out)

        out = self.conv2(out)
        out = self.act2(out)

        out = self.conv3(out)
        out = self.act3(out)

        out = self.conv4(out)
        out = self.act4(out)

        out = self.output(out)

        # out is B x C x D* W x H, with C = 4*num_anchors  out (1,4*9,16,28,28)
        # return out
        out = out.permute(0, 2, 1, 3, 4)  # out(1,16,28,28,4*9)
        # depth = out.shape[1]
        return out

class ClassificationModel(nn.Module):
    def __init__(self, num_features_in=256, num_anchors=9, num_classes=1, prior=0.01, feature_size=256):
        super(ClassificationModel, self).__init__()

        self.num_classes = num_classes
        self.num_anchors = num_anchors

        self.conv1 = nn.Conv3d(num_features_in, feature_size, kernel_size=3, padding=1)
        self.act1 = nn.ReLU()

        self.conv2 = nn.Conv3d(feature_size, feature_size, kernel_size=3, padding=1)
        self.act2 = nn.ReLU()

        self.conv3 = nn.Conv3d(feature_size, feature_size, kernel_size=3, padding=1)
        self.act3 = nn.ReLU()

        self.conv4 = nn.Conv3d(feature_size, feature_size, kernel_size=3, padding=1)
        self.act4 = nn.ReLU()

        self.output = nn.Conv3d(feature_size, num_anchors * num_classes, kernel_size=3, padding=1)
        self.output_act = nn.Sigmoid()

    def forward(self, x):
        out = self.conv1(x)
        out = self.act1(out)

        out = self.conv2(out)
        out = self.act2(out)

        out = self.conv3(out)
        out = self.act3(out)

        out = self.conv4(out)
        out = self.act4(out)

        out = self.output(out)
        out = self.output_act(out)


        # out is B x C x W x H, with C = n_classes + n_anchors
        out1 = out.permute(0, 2, 3, 4, 1)
        batch_size, depth, width, height, channels = out1.shape
        out2 = out1.view(batch_size, depth, width, height, self.num_anchors, self.num_classes)  # 1*16*28*28*9*1
        a = out2.contiguous().view(x.shape[0], depth, -1, self.num_classes)

        return out2.contiguous().view(x.shape[0], depth, -1, self.num_classes)  # 1,*16*28*28*9,1


class SubNet(nn.Module):

    def __init__(self):
        super(SubNet, self).__init__()
        self.Regress = RegressionModel()
        self.Cls = ClassificationModel()
        self.fpn = FeaturePyramid(resnet101())

    def forward(self, x):
        p3, p4, p5 = self.fpn(x)   #56 28 14
        out56 = self.Regress(p3)    #56
        out28 = self.Regress(p4)    #28
        out14 = self.Regress(p5)    #14
        reg = [out14, out28, out56]    # 14,28,56
        return reg


